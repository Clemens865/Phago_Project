[package]
name = "phago-llm"
version.workspace = true
edition.workspace = true
license.workspace = true
repository.workspace = true
authors.workspace = true
description = "LLM integration for Phago semantic intelligence"
documentation = "https://docs.rs/phago-llm"
readme = "README.md"

[dependencies]
phago-core = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = "1"
thiserror = "1"
async-trait = "0.1"

# HTTP client for API calls
reqwest = { version = "0.12", features = ["json"], optional = true }
tokio = { version = "1", features = ["rt-multi-thread", "macros"], optional = true }

# Local LLM support (Ollama)
# Uses same reqwest/tokio as API

[dev-dependencies]
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }

[features]
default = []
# API backends (Claude, OpenAI)
api = ["reqwest", "tokio"]
# Local backends (Ollama)
local = ["reqwest", "tokio"]
# All backends
full = ["api", "local"]
